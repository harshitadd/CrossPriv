{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CrossPriv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/CrossPriv/blob/master/CrossPriv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aoq3s2Yzd15t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install syft==0.2.6 --quiet \n",
        "!pip install pydicom --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6bD7JbBq0D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import syft as sy\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import time\n",
        "import csv \n",
        "import copy\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from syft.frameworks.torch.fl import utils\n",
        "from syft.workers.websocket_client import WebsocketClientWorker\n",
        "import pydicom \n",
        "import pandas as pd \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwuyc_DerKUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeNonFedData():\n",
        "  dcm_path=os.listdir('/content/drive/My Drive/minibatch_large/')\n",
        "  dcm_data={}\n",
        "  alpha = 1.5 \n",
        "  beta = 0\n",
        "  labels=[]\n",
        "  pid=[]\n",
        "  dicom=[]\n",
        "  label=[]\n",
        "  for file in dcm_path:\n",
        "    name = '/content/drive/My Drive/minibatch_large/' + file\n",
        "    temp = pydicom.dcmread(name)\n",
        "    image = temp.pixel_array\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    adjusted = cv2.resize(image,(128,128))\n",
        "    dcm_data[file]=adjusted  \n",
        "  with open('/content/drive/My Drive/Fed_Covid/stage_2_train_labels.csv','r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "      labels.append(row)  \n",
        "  scaler = MinMaxScaler()\n",
        "  cid = 0\n",
        "  for PID in labels:\n",
        "    for key in dcm_data:\n",
        "      if(key[:-4]==PID[0]):\n",
        "        l=[]\n",
        "        for val in dcm_data[key]:\n",
        "          l.append(scaler.fit_transform(val))\n",
        "        l = np.reshape(l,(3,128,128))\n",
        "        dicom.append(l)\n",
        "        label.append(int(PID[5]))\n",
        "  \n",
        "  return dicom,label\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuoufluUrqEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dicom, label = makeNonFedData()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug6_GHABdh65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd4f7171-23ea-4800-efac-722f06bd4e08"
      },
      "source": [
        "print(len(dicom),len(label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4270 4270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOeS4TuIgogO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 8\n",
        "        self.test_batch_size = 4\n",
        "        self.epochs = 25\n",
        "        self.lr = 0.001\n",
        "        self.log_interval = 10\n",
        "args = Arguments()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td7w-9SHFgaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dicom,label,test_size=0.3)\n",
        "test_df = pd.DataFrame()\n",
        "test_df['features']=x_test\n",
        "test_df['labels']=y_test\n",
        "x_train= np.array(x_train)\n",
        "y_train= np.array(y_train)\n",
        "x_test= np.array(x_test)\n",
        "y_test= np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8KCNM1rpsJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class data_maker(Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "        self.data = images \n",
        "        self.targets = labels \n",
        "\n",
        "        self.to_torchtensor()\n",
        "        \n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def to_torchtensor(self):      \n",
        "      self.data=torch.from_numpy(self.data)\n",
        "      self.labels=torch.from_numpy(self.targets)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "      sample=self.data[idx]\n",
        "      target=self.targets[idx]\n",
        "      return sample,target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HjuI6IJnOo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hook = sy.TorchHook(torch)\n",
        "hospital = sy.VirtualWorker(hook, id=\"hospital\")  \n",
        "clinic = sy.VirtualWorker(hook, id=\"clinic\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGOtNPrLcCXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "federated_train_data = data_maker(x_train,y_train).federate((hospital,clinic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVmlJAfUcCUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader(federated_train_data,batch_size=args.batch_size)\n",
        "test_data = data_maker(x_test,y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpiILdmui8ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()  \n",
        "        self.conv1 = nn.Conv2d(3,32, kernel_size=8, stride = 2)  \n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=4,stride=2,padding=0)  \n",
        "        self.conv2 = nn.Conv2d(32, 64, 8)\n",
        "        self.pool2 = nn.MaxPool2d(8,8,padding=0)\n",
        "\n",
        "        # Linear Layers \n",
        "        \n",
        "        self.fc1 = nn.Linear(64*2*2, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # print(x.shape)\n",
        "        x = self.pool1(x)\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        # print(x.shape)\n",
        "        x = self.pool2(x)\n",
        "        # print(x.shape)\n",
        "        x = x.view(-1,64*2*2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        " \n",
        "        return F.log_softmax(x,dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6NZuEi-lmCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net().double()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBeC0JqCE2oM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): \n",
        "        model.send(data.location) \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get()\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get()\n",
        "            # print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            #     epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),\n",
        "            #     100. * batch_idx / len(federated_train_loader), loss.item()))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Ei8_ogE2mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model,test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    #criterion = F.nll_loss()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHQk6NAVE2j9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) \n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model,  test_loader)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEO7n4GLf_zA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hospital_model = Net().double()\n",
        "# clinic_model = Net().double()\n",
        "# hospital_optimizer = optim.Adam(hospital_model.parameters(), lr=0.0001)\n",
        "# clinic_optimizer = optim.Adam(clinic_model.parameters(), lr=0.0001)\n",
        "# models = [hospital_model, clinic_model]\n",
        "# optimizers = [hospital_optimizer, clinic_optimizer]\n",
        "# compute_nodes = [hospital, clinic]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}