{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreVID_PySyft_Federated_Averaging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/CrossPriv/blob/master/PreVID_PySyft_Federated_Averaging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aoq3s2Yzd15t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install syft==0.2.6 --quiet \n",
        "# !pip install pydicom --quiet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6bD7JbBq0D6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "977bf9d4-2f69-47ea-a188-8abdc8ad4e11"
      },
      "source": [
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import syft as sy\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import time\n",
        "import csv \n",
        "import copy\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from syft.frameworks.torch.fl import utils\n",
        "from syft.workers.websocket_client import WebsocketClientWorker\n",
        "import pydicom \n",
        "import pandas as pd \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwuyc_DerKUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeNonFedData():\n",
        "  dcm_path=os.listdir('/content/drive/My Drive/Fed_Covid/minibatch/')\n",
        "  dcm_data={}\n",
        "  alpha = 1.5 \n",
        "  beta = 0\n",
        "  labels=[]\n",
        "  pid=[]\n",
        "  dicom=[]\n",
        "  label=[]\n",
        "  for file in dcm_path:\n",
        "    name = '/content/drive/My Drive/Fed_Covid/minibatch/' + file\n",
        "    temp = pydicom.dcmread(name)\n",
        "    image = temp.pixel_array\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    adjusted = cv2.resize(image,(128,128))\n",
        "    dcm_data[file]=adjusted  \n",
        "  with open('/content/drive/My Drive/Fed_Covid/stage_2_train_labels.csv','r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "      labels.append(row)  \n",
        "  scaler = MinMaxScaler()\n",
        "  cid = 0\n",
        "  for PID in labels:\n",
        "    for key in dcm_data:\n",
        "      if(key[:-4]==PID[0]):\n",
        "        l=[]\n",
        "        for val in dcm_data[key]:\n",
        "          l.append(scaler.fit_transform(val))\n",
        "        l = np.reshape(l,(3,128,128))\n",
        "        dicom.append(l)\n",
        "        label.append(int(PID[5]))\n",
        "  \n",
        "  return dicom,label\n",
        "    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuoufluUrqEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dicom, label = makeNonFedData()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOeS4TuIgogO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 4\n",
        "        self.test_batch_size = 4\n",
        "        self.epochs = 1\n",
        "args = Arguments()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td7w-9SHFgaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dicom,label,test_size=0.3)\n",
        "test_df = pd.DataFrame()\n",
        "test_df['features']=x_test\n",
        "test_df['labels']=y_test\n",
        "x_train= np.array(x_train)\n",
        "y_train= np.array(y_train)\n",
        "x_test= np.array(x_test)\n",
        "y_test= np.array(y_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8KCNM1rpsJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class data_maker(Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "        self.data = images \n",
        "        self.targets = labels \n",
        "\n",
        "        self.to_torchtensor()\n",
        "        \n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def to_torchtensor(self):      \n",
        "      self.data=torch.from_numpy(self.data)\n",
        "      self.labels=torch.from_numpy(self.targets)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "      sample=self.data[idx]\n",
        "      target=self.targets[idx]\n",
        "      return sample,target"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HjuI6IJnOo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hook = sy.TorchHook(torch)\n",
        "hospital = sy.VirtualWorker(hook, id=\"hospital\")  \n",
        "clinic = sy.VirtualWorker(hook, id=\"clinic\")  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGOtNPrLcCXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "federated_train_data = data_maker(x_train,y_train).federate((hospital,clinic))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVmlJAfUcCUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader(federated_train_data,batch_size=args.batch_size)\n",
        "test_data = data_maker(x_test,y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.test_batch_size)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpiILdmui8ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()  \n",
        "        self.conv1 = nn.Conv2d(3,32, kernel_size=8, stride = 2)  \n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=4,stride=2,padding=0)  \n",
        "        self.conv2 = nn.Conv2d(32, 64, 8)\n",
        "        self.pool2 = nn.MaxPool2d(8,8,padding=0)\n",
        "\n",
        "        # Linear Layers \n",
        "        \n",
        "        self.fc1 = nn.Linear(64*2*2, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # print(x.shape)\n",
        "        x = self.pool1(x)\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        # print(x.shape)\n",
        "        x = self.pool2(x)\n",
        "        # print(x.shape)\n",
        "        x = x.view(-1,64*2*2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        " \n",
        "        return F.log_softmax(x,dim=1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6NZuEi-lmCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_model = Net().double()\n",
        "clinic_model = Net().double()\n",
        "hospital_optimizer = optim.Adam(hospital_model.parameters(), lr=0.0001)\n",
        "clinic_optimizer = optim.Adam(clinic_model.parameters(), lr=0.0001)\n",
        "models = [hospital_model, clinic_model]\n",
        "optimizers = [hospital_optimizer, clinic_optimizer]\n",
        "model = Net().double()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xTEMi9Alujt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compute_nodes = [hospital, clinic]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-DJE7Gfl3md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update(data, target, model, optimizer):\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    model.send(data.location) \n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    out = loss(output, target)\n",
        "    out.backward()\n",
        "    optimizer.step()\n",
        "    return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnjt9JjcmUS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  for batch_idx, (data, target) in enumerate(federated_train_loader):\n",
        "    for index in range(len(compute_nodes)):\n",
        "      models[index] = update(data,target,models[index],optimizers[index]) \n",
        "    for model in models:\n",
        "      model.get()\n",
        "    return utils.federated_avg({\"hospital\": models[0],\"clinic\":models[1]}) \n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cehV3xzNRUd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c15c987-c26f-420f-8130-519bf71530b2"
      },
      "source": [
        "for i,val in enumerate(federated_train_loader):\n",
        "  print(val[0][0][0][0][0])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Wrapper)>[PointerTensor | me:49669881127 -> hospital:62090774770]\n",
            "(Wrapper)>[PointerTensor | me:99650303896 -> hospital:96417058942]\n",
            "(Wrapper)>[PointerTensor | me:56268577334 -> hospital:4376112198]\n",
            "(Wrapper)>[PointerTensor | me:58837496549 -> hospital:87139879855]\n",
            "(Wrapper)>[PointerTensor | me:87132144047 -> hospital:1140471215]\n",
            "(Wrapper)>[PointerTensor | me:95986700245 -> hospital:68118093444]\n",
            "(Wrapper)>[PointerTensor | me:82160064218 -> hospital:36666929132]\n",
            "(Wrapper)>[PointerTensor | me:10447572305 -> hospital:60526882959]\n",
            "(Wrapper)>[PointerTensor | me:95063713365 -> hospital:82608196782]\n",
            "(Wrapper)>[PointerTensor | me:98663237637 -> hospital:12532750603]\n",
            "(Wrapper)>[PointerTensor | me:50081789567 -> hospital:58863684355]\n",
            "(Wrapper)>[PointerTensor | me:92288627231 -> hospital:62430943806]\n",
            "(Wrapper)>[PointerTensor | me:36373331765 -> hospital:19609013017]\n",
            "(Wrapper)>[PointerTensor | me:82397478200 -> hospital:13819709098]\n",
            "(Wrapper)>[PointerTensor | me:77829321630 -> hospital:74915042267]\n",
            "(Wrapper)>[PointerTensor | me:34514028500 -> hospital:48763090774]\n",
            "(Wrapper)>[PointerTensor | me:48602716940 -> hospital:57400863850]\n",
            "(Wrapper)>[PointerTensor | me:76732832613 -> hospital:97934019457]\n",
            "(Wrapper)>[PointerTensor | me:75128582771 -> hospital:9583709660]\n",
            "(Wrapper)>[PointerTensor | me:1583929853 -> hospital:45442240801]\n",
            "(Wrapper)>[PointerTensor | me:58119463596 -> hospital:72904285536]\n",
            "(Wrapper)>[PointerTensor | me:59017727384 -> hospital:17159439619]\n",
            "(Wrapper)>[PointerTensor | me:87999434883 -> hospital:77729994867]\n",
            "(Wrapper)>[PointerTensor | me:62212221160 -> hospital:3798626058]\n",
            "(Wrapper)>[PointerTensor | me:32886560952 -> hospital:5095023032]\n",
            "(Wrapper)>[PointerTensor | me:37640922945 -> hospital:56855327454]\n",
            "(Wrapper)>[PointerTensor | me:57613886008 -> hospital:57093690591]\n",
            "(Wrapper)>[PointerTensor | me:66727630304 -> hospital:68745860733]\n",
            "(Wrapper)>[PointerTensor | me:98134225403 -> hospital:10948565693]\n",
            "(Wrapper)>[PointerTensor | me:49269707378 -> hospital:33939674261]\n",
            "(Wrapper)>[PointerTensor | me:39591951662 -> hospital:97789348016]\n",
            "(Wrapper)>[PointerTensor | me:49497482586 -> hospital:97712560225]\n",
            "(Wrapper)>[PointerTensor | me:55664507049 -> hospital:60414955648]\n",
            "(Wrapper)>[PointerTensor | me:40682406476 -> hospital:99578797516]\n",
            "(Wrapper)>[PointerTensor | me:37128126129 -> hospital:47280659821]\n",
            "(Wrapper)>[PointerTensor | me:41222607608 -> hospital:65882701031]\n",
            "(Wrapper)>[PointerTensor | me:13384343222 -> hospital:46614889735]\n",
            "(Wrapper)>[PointerTensor | me:17023898898 -> hospital:73152397424]\n",
            "(Wrapper)>[PointerTensor | me:10458809863 -> clinic:20735954919]\n",
            "(Wrapper)>[PointerTensor | me:87988413190 -> clinic:83674774709]\n",
            "(Wrapper)>[PointerTensor | me:93675218065 -> clinic:4414327621]\n",
            "(Wrapper)>[PointerTensor | me:26362263131 -> clinic:5710811631]\n",
            "(Wrapper)>[PointerTensor | me:20218598529 -> clinic:86422258507]\n",
            "(Wrapper)>[PointerTensor | me:51745837083 -> clinic:22436680778]\n",
            "(Wrapper)>[PointerTensor | me:67964004535 -> clinic:56314468342]\n",
            "(Wrapper)>[PointerTensor | me:85192099166 -> clinic:46480577519]\n",
            "(Wrapper)>[PointerTensor | me:87792060056 -> clinic:32522809261]\n",
            "(Wrapper)>[PointerTensor | me:67249335676 -> clinic:71323267520]\n",
            "(Wrapper)>[PointerTensor | me:45886983290 -> clinic:71351718910]\n",
            "(Wrapper)>[PointerTensor | me:47325058266 -> clinic:28616974293]\n",
            "(Wrapper)>[PointerTensor | me:29875201368 -> clinic:77813008577]\n",
            "(Wrapper)>[PointerTensor | me:61430264076 -> clinic:5211001757]\n",
            "(Wrapper)>[PointerTensor | me:72309462399 -> clinic:72757445144]\n",
            "(Wrapper)>[PointerTensor | me:49483552785 -> clinic:60856141218]\n",
            "(Wrapper)>[PointerTensor | me:74078262912 -> clinic:47750034632]\n",
            "(Wrapper)>[PointerTensor | me:78460091362 -> clinic:28920832910]\n",
            "(Wrapper)>[PointerTensor | me:12421436510 -> clinic:20363096567]\n",
            "(Wrapper)>[PointerTensor | me:68557118107 -> clinic:83318353955]\n",
            "(Wrapper)>[PointerTensor | me:23132405175 -> clinic:93325163648]\n",
            "(Wrapper)>[PointerTensor | me:13714225373 -> clinic:50978581487]\n",
            "(Wrapper)>[PointerTensor | me:37905115209 -> clinic:77862921464]\n",
            "(Wrapper)>[PointerTensor | me:66566531760 -> clinic:42108246392]\n",
            "(Wrapper)>[PointerTensor | me:54671221152 -> clinic:33832451181]\n",
            "(Wrapper)>[PointerTensor | me:79895184690 -> clinic:71348970893]\n",
            "(Wrapper)>[PointerTensor | me:88822894016 -> clinic:39922299181]\n",
            "(Wrapper)>[PointerTensor | me:41818205666 -> clinic:34090917519]\n",
            "(Wrapper)>[PointerTensor | me:43061140268 -> clinic:6181289628]\n",
            "(Wrapper)>[PointerTensor | me:25545698387 -> clinic:71597544847]\n",
            "(Wrapper)>[PointerTensor | me:44957732826 -> clinic:42757101619]\n",
            "(Wrapper)>[PointerTensor | me:24228518341 -> clinic:88028849768]\n",
            "(Wrapper)>[PointerTensor | me:93096516797 -> clinic:67990853447]\n",
            "(Wrapper)>[PointerTensor | me:56580962506 -> clinic:56327493313]\n",
            "(Wrapper)>[PointerTensor | me:21367206768 -> clinic:38309057342]\n",
            "(Wrapper)>[PointerTensor | me:24670871332 -> clinic:82989348318]\n",
            "(Wrapper)>[PointerTensor | me:821678729 -> clinic:52702115882]\n",
            "(Wrapper)>[PointerTensor | me:68736106810 -> clinic:20120283804]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE7FcMWEQ-rO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "eb94ed1f-67f1-4f15-b7c9-906b79361e11"
      },
      "source": [
        "for i,val in enumerate(test_loader):\n",
        "  print(val[0][0][0][0][0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0274, dtype=torch.float64)\n",
            "tensor(0.0152, dtype=torch.float64)\n",
            "tensor(0.0934, dtype=torch.float64)\n",
            "tensor(0., dtype=torch.float64)\n",
            "tensor(0.7956, dtype=torch.float64)\n",
            "tensor(1., dtype=torch.float64)\n",
            "tensor(0.0909, dtype=torch.float64)\n",
            "tensor(0.9360, dtype=torch.float64)\n",
            "tensor(0.5075, dtype=torch.float64)\n",
            "tensor(0.6449, dtype=torch.float64)\n",
            "tensor(1.0000, dtype=torch.float64)\n",
            "tensor(0.3404, dtype=torch.float64)\n",
            "tensor(0.0110, dtype=torch.float64)\n",
            "tensor(0., dtype=torch.float64)\n",
            "tensor(0., dtype=torch.float64)\n",
            "tensor(0.1429, dtype=torch.float64)\n",
            "tensor(0.0465, dtype=torch.float64)\n",
            "tensor(0.2174, dtype=torch.float64)\n",
            "tensor(0., dtype=torch.float64)\n",
            "tensor(1., dtype=torch.float64)\n",
            "tensor(0.9771, dtype=torch.float64)\n",
            "tensor(0., dtype=torch.float64)\n",
            "tensor(0.0133, dtype=torch.float64)\n",
            "tensor(0.3661, dtype=torch.float64)\n",
            "tensor(0.5419, dtype=torch.float64)\n",
            "tensor(0.0156, dtype=torch.float64)\n",
            "tensor(0.0765, dtype=torch.float64)\n",
            "tensor(0., dtype=torch.float64)\n",
            "tensor(0.6449, dtype=torch.float64)\n",
            "tensor(0.3012, dtype=torch.float64)\n",
            "tensor(0.0131, dtype=torch.float64)\n",
            "tensor(0., dtype=torch.float64)\n",
            "tensor(0.0056, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9jG8P7EntJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(federated_model):\n",
        "  federated_model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        out = loss(output,target)\n",
        "        test_loss += out\n",
        "        #print('Test loss of the iteration on local model - ',test_loss)\n",
        "        pred = output.argmax(1, keepdim=True)\n",
        "        # print('predicted val',pred)\n",
        "        # print('target val',target)\n",
        "        correct += pred.eq(target.view_as(pred))\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print(correct)\n",
        "  print('For Global Model Test loss:' + str(test_loss))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg1J-ojznOWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5bd39204-8120-436a-8848-68389f8a634d"
      },
      "source": [
        "for epoch in range(2):\n",
        "  start_time = time.time()\n",
        "  print(f\"Epoch Number {epoch}\")\n",
        "  federated_model = train()\n",
        "  test(federated_model)\n",
        "  total_time = time.time() - start_time \n",
        "  print('Comm time', round(total_time,2),'s\\n')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch Number 0\n",
            "Test loss of the iteration on local model -  tensor(0.6888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(1.3792, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(2.0667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(2.7630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(3.4558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(4.1445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(4.8380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(5.5260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(6.2152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(6.9060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(7.5978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(8.2861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(8.9737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(9.6622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(10.3502, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(11.0389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(11.7281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(12.4194, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(13.1070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(13.7972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(14.4878, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(15.1760, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(15.8662, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(16.5578, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(17.2484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(17.9394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(18.6284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(19.3168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(20.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(20.6974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(21.3891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(22.0817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(22.7701, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "For Global Model Test loss:tensor(0.1765, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "Comm time 2.52 s\n",
            "\n",
            "Epoch Number 1\n",
            "Test loss of the iteration on local model -  tensor(0.6888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(1.3792, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(2.0667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(2.7630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(3.4558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(4.1445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(4.8380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(5.5260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(6.2152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(6.9060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(7.5978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(8.2861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(8.9737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(9.6622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(10.3502, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(11.0389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(11.7281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(12.4194, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(13.1070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(13.7972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(14.4878, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(15.1760, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(15.8662, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(16.5578, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(17.2484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(17.9394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(18.6284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(19.3168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(20.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(20.6974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(21.3891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(22.0817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Test loss of the iteration on local model -  tensor(22.7701, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "For Global Model Test loss:tensor(0.1765, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "Comm time 2.44 s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zib321mbOzFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}